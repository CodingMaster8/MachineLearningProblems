# Instrucciones

Resuelve los siguientes ejercicios en Python y responde a los planteamientos indicados en cada uno. Incluye en tu reporte las salidas de tus programas, y una **conclusi√≥n breve** para esta actividad sobre la efectividad de los m√©todos probados.

---

## Ejercicio 1 (25 puntos)

1. Carga la base de datos **Iris** y grafica las observaciones inclu√≠das en este conjunto de datos utilizando pares de variables predictoras. Representa la clase de cada observaci√≥n con un color distinto.
2. **Preguntas**:
   - ¬øQu√© representan las variables incluidas en la base de datos?
   - ¬øConsideras que las variables predictoras tienen informaci√≥n suficiente para determinar la clase de cada uno de los tipos de datos?
3. Entrena un clasificador **SVM lineal** con todos los datos.
   - Aseg√∫rate de usar el par√°metro `kernel='linear'`.
4. Inventa **10 nuevas observaciones**, y verifica el resultado obtenido al evaluar el clasificador con estos nuevos datos.
5. Eval√∫a el modelo de clasificaci√≥n con **k-fold cross validation** (k = 10).
   - Calcula:
     - **Exactitud** del clasificador (accuracy),
     - **Precisi√≥n** y
     - **Recall** para cada clase.
   - Puedes utilizar la **matriz de confusi√≥n** calculada con `sklearn`.

---

## Ejercicio 2 (25 puntos)

1. Carga la base de datos **Wine** y muestra las variables predictoras de este conjunto de datos.
2. **Preguntas**:
   - ¬øCu√°ntas variables y observaciones por clase hay en este conjunto de datos?
   - ¬øQu√© representan los predictores?
3. Calcula la exactitud de los siguientes modelos de clasificaci√≥n con **k-fold cross validation (k = 5)** para la base de datos Wine:
   - **SVM lineal** (`kernel='linear'`)
   - **SVM con base radial** (`kernel='rbf'`)
   - **k-NN** (para `k = 3`)
   - **√Årbol de decisi√≥n**
   - Cualquier otro clasificador que est√© implementado en `sklearn`
4. Indica **con qu√© clasificador se obtuvieron los mejores resultados**.

---

## Ejercicio 3 (25 puntos)

Con este **conjunto de datos misteriosos** (con tres clases):

1. Encuentra el mejor valor del par√°metro `k` del clasificador **k-NN** utilizando validaci√≥n cruzada. Para ello:
   - Grafica el rendimiento obtenido con validaci√≥n cruzada para diferentes valores del par√°metro `k`. Se recomienda: `k = 1, 2, 3, ..., 40`.
   - Selecciona el **mejor valor de k** con los resultados del punto anterior.
   - Eval√∫a con **validaci√≥n cruzada anidada** el rendimiento del modelo incluyendo **selecci√≥n de hiperpar√°metros**.

2. Repite lo anterior, pero para un clasificador **SVM lineal** usando diferentes valores del factor de regularizaci√≥n:  
   `C = 0.000001, 0.000002, 0.000003, ..., 0.0001`

3. Repite el punto 1, pero con un clasificador **SVM de base radial**, para diferentes valores del par√°metro del kernel:  
   `gamma = 0.000001, 0.000002, 0.000003, ..., 0.0002`

> üìå En el archivo de datos de este ejercicio, la **primera columna corresponde a la etiqueta o clase (1, 2 o 3)**, y el resto de las columnas son variables o predictores.

---

## Problema 4 (25 puntos)

Con otro **conjunto de datos misteriosos** (con 4 clases):

1. Seleccionen un modelo de clasificaci√≥n **(que no sea SVM)** y utilicen el m√©todo **filter** para reducir el n√∫mero de caracter√≠sticas. Prueben limitando el n√∫mero de caracter√≠sticas a:  
   `10, 20, 30, 40, ..., 100`

2. Utilicen el m√©todo de **selecci√≥n de caracter√≠sticas secuencial (Wrapper)** para reducir el n√∫mero de caracter√≠sticas. Prueben con los siguientes l√≠mites:  
   `1, 2, 3, 4, 5, 6, 7, 8, 9, 10`

3. Utilicen el m√©todo de **selecci√≥n de caracter√≠sticas recursivo (Filter-Wrapper)** para reducir el n√∫mero de caracter√≠sticas. Prueben con los siguientes l√≠mites:  
   `1, 2, 3, 4, 5, 6, 7, 8, 9, 10`

---

### Preguntas finales:

- ¬øQu√© m√©todo les permiti√≥ obtener un menor n√∫mero de caracter√≠sticas?
- ¬øCu√°l m√©todo consideras que es m√°s r√°pido para encontrar una soluci√≥n?
